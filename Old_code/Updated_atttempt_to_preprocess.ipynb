{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n9N4Je8o48lR"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-WWgnKx24-YQ",
        "outputId": "2aed8e50-b2de-4054-ff89-9ec715c18405"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-5c788b239427>:1: DtypeWarning: Columns (16) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  data=pd.read_csv('/content/drive/MyDrive/Battery Data/battery.csv')\n"
          ]
        }
      ],
      "source": [
        "data=pd.read_csv('/content/drive/MyDrive/Battery Data/battery.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ij36yw3y4_6L"
      },
      "outputs": [],
      "source": [
        "property_groups = {prop: df for prop, df in data.groupby('Property')}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rbNL-niu5MF0"
      },
      "outputs": [],
      "source": [
        "shared_key=[]\n",
        "shared_pop=[]\n",
        "for key, df in property_groups.items():\n",
        "    shared_key.append(key)\n",
        "    shared_pop.append(df.shape[0])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c3XCHLKB5ONM"
      },
      "outputs": [],
      "source": [
        "#\n",
        "# Group by 'Property' and collect sets of 'Name' values\n",
        "from collections import defaultdict\n",
        "\n",
        "property_name_map = defaultdict(set)\n",
        "\n",
        "for prop, group_df in data.groupby('Property'):\n",
        "    property_name_map[prop] = set(group_df['Name'])\n",
        "\n",
        "# Compare sets to find overlaps\n",
        "from itertools import combinations\n",
        "\n",
        "shared_names = {}\n",
        "shared_name_dfs = {}\n",
        "\n",
        "\n",
        "for (prop1, names1), (prop2, names2) in combinations(property_name_map.items(), 2):\n",
        "    overlap = names1 & names2\n",
        "    if overlap:\n",
        "        shared_names[(prop1, prop2)] = overlap\n",
        "\n",
        "# Display shared names between property groups\n",
        "for (prop1, prop2), names in shared_names.items():\n",
        "  filtered_df = data[\n",
        "    (data['Property'].isin([prop1, prop2])) &\n",
        "        (data['Name'].isin(names))\n",
        "    ]\n",
        "  shared_name_dfs[(prop1, prop2)] = filtered_df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j1m-2sKQ5QcK"
      },
      "outputs": [],
      "source": [
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Group by 'Extracted_name'\n",
        "g = df.groupby('Extracted_name')\n",
        "\n",
        "# Create a dictionary to store DataFrames for each Extracted_name with different Property values combined\n",
        "grouped_dfs = {}\n",
        "\n",
        "# Loop through each group and combine their rows\n",
        "for name, group in g:\n",
        "    # Append all the rows with the same Extracted_name into a single DataFrame\n",
        "    group = group.drop_duplicates(subset='Property', keep='first')\n",
        "    grouped_dfs[name] = group  # Store the whole group (with all Property values)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wj8-D9gq5U91"
      },
      "outputs": [],
      "source": [
        "from itertools import combinations\n",
        "all_data = pd.concat(grouped_dfs.values())\n",
        "\n",
        "# Get all unique property combinations (pairwise)\n",
        "unique_properties = all_data['Property'].unique()\n",
        "property_pairs = combinations(unique_properties, 2)\n",
        "\n",
        "# Dictionary to store the final dataframes\n",
        "final_pairwise_dfs = {}\n",
        "\n",
        "for prop1, prop2 in property_pairs:\n",
        "    # Filter rows where Property is either prop1 or prop2\n",
        "    filtered = all_data[all_data['Property'].isin([prop1, prop2])]\n",
        "\n",
        "    # Group by Extracted_name and keep only those with both properties\n",
        "    grouped = filtered.groupby('Extracted_name')\n",
        "    valid_entries = []\n",
        "\n",
        "    for name, group in grouped:\n",
        "        if set([prop1, prop2]).issubset(set(group['Property'])):\n",
        "            # Extract only the two rows and pivot to a single row\n",
        "            pivoted = group.set_index('Property')['Value'].loc[[prop1, prop2]]\n",
        "            pivoted_df = pd.DataFrame(pivoted).T\n",
        "            pivoted_df['Extracted_name'] = name\n",
        "            valid_entries.append(pivoted_df)\n",
        "\n",
        "    # Combine all valid entries into one DataFrame\n",
        "    if valid_entries:\n",
        "        final_df = pd.concat(valid_entries, ignore_index=True)\n",
        "        # Reorder columns to have name first\n",
        "        cols = ['Extracted_name', prop1, prop2]\n",
        "        final_pairwise_dfs[f\"{prop1}-{prop2}\"] = final_df[cols]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n0Gy8tOl5c1O"
      },
      "outputs": [],
      "source": [
        "final_pairwise_dfs['Capacity-Conductivity'].shape[0]\n",
        "key_name=[]\n",
        "key_pop=[]\n",
        "for key in final_pairwise_dfs.keys():\n",
        "  key_name.append(str(key))\n",
        "  key_pop.append(int(final_pairwise_dfs[key].shape[0]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mA3ei3qk5ndT",
        "outputId": "9aa2b555-433e-46d8-e938-0c745e85ef60"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: jarvis-tools in /usr/local/lib/python3.11/dist-packages (2024.10.30)\n",
            "Requirement already satisfied: numpy>=1.20.1 in /usr/local/lib/python3.11/dist-packages (from jarvis-tools) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from jarvis-tools) (1.15.2)\n",
            "Requirement already satisfied: matplotlib>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from jarvis-tools) (3.10.0)\n",
            "Requirement already satisfied: joblib>=0.14.1 in /usr/local/lib/python3.11/dist-packages (from jarvis-tools) (1.4.2)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.11/dist-packages (from jarvis-tools) (2.32.3)\n",
            "Requirement already satisfied: toolz>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from jarvis-tools) (0.12.1)\n",
            "Requirement already satisfied: xmltodict>=0.11.0 in /usr/local/lib/python3.11/dist-packages (from jarvis-tools) (0.14.2)\n",
            "Requirement already satisfied: tqdm>=4.41.1 in /usr/local/lib/python3.11/dist-packages (from jarvis-tools) (4.67.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from jarvis-tools) (1.6.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.0.0->jarvis-tools) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.0.0->jarvis-tools) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.0.0->jarvis-tools) (4.57.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.0.0->jarvis-tools) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.0.0->jarvis-tools) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.0.0->jarvis-tools) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.0.0->jarvis-tools) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.0.0->jarvis-tools) (2.9.0.post0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->jarvis-tools) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->jarvis-tools) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->jarvis-tools) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->jarvis-tools) (2025.4.26)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->jarvis-tools) (3.6.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=3.0.0->jarvis-tools) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install jarvis-tools\n",
        "import jarvis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WvlXVDXn5wsB",
        "outputId": "8a66a664-f06f-49ec-83b2-69b66734fc8d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Obtaining 3D dataset 76k ...\n",
            "Reference:https://www.nature.com/articles/s41524-020-00440-1\n",
            "Other versions:https://doi.org/10.6084/m9.figshare.6815699\n",
            "Loading the zipfile...\n",
            "Loading completed.\n",
            "Obtaining 3D dataset 55k ...\n",
            "Reference:https://www.nature.com/articles/s41524-020-00440-1\n",
            "Other versions:https://doi.org/10.6084/m9.figshare.6815699\n",
            "Loading the zipfile...\n",
            "Loading completed.\n"
          ]
        }
      ],
      "source": [
        "from jarvis.db.figshare import data\n",
        "d=data('dft_3d')\n",
        "didf=pd.DataFrame(d)[['jid','formula']]\n",
        "g=data('cfid_3d')\n",
        "oqmd = pd.DataFrame(g)[['jid', 'formula']]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "h=data('dft_2d_2021')\n",
        "dft2_ = pd.DataFrame(h)[['jid', 'formula']]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GCf3XaG-Tpyk",
        "outputId": "7c9f49e0-5de5-4126-a566-d38944be8cc5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Obtaining 2D dataset 1.1k ...\n",
            "Reference:https://www.nature.com/articles/s41524-020-00440-1\n",
            "Loading the zipfile...\n",
            "Loading completed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "j=data('dft_2d')\n",
        "dft2 = pd.DataFrame(j)[['jid', 'formula']]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VzFtN-0JT2Mk",
        "outputId": "503a6959-be07-4304-949e-7d1dfc573f1b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Obtaining 2D dataset 1.1k ...\n",
            "Reference:https://www.nature.com/articles/s41524-020-00440-1\n",
            "Other versions:https://doi.org/10.6084/m9.figshare.6815705\n",
            "Loading the zipfile...\n",
            "Loading completed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "k=data('dft_3d_2021')\n",
        "dft3d = pd.DataFrame(k)[['jid', 'formula']]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VKmlCF25ieKh",
        "outputId": "f27d9070-17d3-4350-9582-654742acab4d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Obtaining 3D dataset 55k ...\n",
            "Reference:https://www.nature.com/articles/s41524-020-00440-1\n",
            "Loading the zipfile...\n",
            "Loading completed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "l=data('jff')\n",
        "jff = pd.DataFrame(l)[['jid', 'formula']]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p73HplC0iuo8",
        "outputId": "e93e214e-cff7-4494-9ad8-9645a7309108"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Obtaining JARVIS-FF 2k ...\n",
            "Reference:https://www.nature.com/articles/s41524-020-00440-1\n",
            "Loading the zipfile...\n",
            "Loading completed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "m=data('qe_tb')\n",
        "qetb=pd.DataFrame(m)[['jid','formula']]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jIP697bDi3sR",
        "outputId": "e770c2b9-fc19-4e98-e237-0ae5f266449e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Obtaining QETB dataset 860k...\n",
            "Reference:https://arxiv.org/abs/2112.11585\n",
            "Loading the zipfile...\n",
            "Loading completed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#creating dataframes for all types of data\n",
        "capacity = property_groups['Capacity']\n",
        "voltage=property_groups['Voltage']\n",
        "energy=property_groups['Energy']\n",
        "columbic=property_groups['Coulombic Efficiency']\n",
        "conductivity=property_groups['Conductivity']\n",
        "voltage_capacity=final_pairwise_dfs['Voltage-Capacity']\n",
        "voltage_conductivity=final_pairwise_dfs['Voltage-Conductivity']\n",
        "voltage_energy=final_pairwise_dfs['Voltage-Energy']\n",
        "voltage_columbic=final_pairwise_dfs['Voltage-Coulombic Efficiency']\n",
        "capacity_conductivity=final_pairwise_dfs['Capacity-Conductivity']\n",
        "capacity_energy=final_pairwise_dfs['Capacity-Energy']\n",
        "capacity_columbic=final_pairwise_dfs['Capacity-Coulombic Efficiency']\n",
        "conductivity_energy=final_pairwise_dfs['Conductivity-Energy']\n",
        "conductivity_columbic=final_pairwise_dfs['Conductivity-Coulombic Efficiency']\n",
        "energy_columbic=final_pairwise_dfs['Energy-Coulombic Efficiency']\n",
        "\n"
      ],
      "metadata": {
        "id": "3iNjQ5V3pEPZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "from fractions import Fraction\n",
        "import ast\n",
        "\n",
        "# Pre-index all dataframes\n",
        "for df in [oqmd, dft2, dft2_, dft3d, jff, qetb, didf]:\n",
        "    if 'formula' in df.columns:\n",
        "        df['formula'] = df['formula'].astype(str)\n",
        "        df.set_index('formula', inplace=True, drop=False)\n",
        "\n",
        "# Combine all formula→jid mappings into one dictionary\n",
        "formula_to_jid = {}\n",
        "\n",
        "for df in [oqmd, dft2, dft2_, dft3d, jff, qetb, didf]:\n",
        "    if 'formula' in df.columns and 'jid' in df.columns:\n",
        "        formula_to_jid.update(df[['formula', 'jid']].dropna().set_index('formula')['jid'].to_dict())\n",
        "\n",
        "def gcd(a, b):\n",
        "    while b:\n",
        "        a, b = b, a % b\n",
        "    return a\n",
        "\n",
        "def normalize_formula(formula):\n",
        "    tokens = re.findall(r'([A-Z][a-z]*)(\\d*)', formula)\n",
        "    tokens = sorted([(el, int(cnt) if cnt else 1) for el, cnt in tokens])\n",
        "    return ''.join([f\"{el}{cnt if cnt > 1 else ''}\" for el, cnt in tokens])\n",
        "\n",
        "def generate_empirical_formula_from_dict(element_dict):\n",
        "    try:\n",
        "        element_dict = {k: float(v) for k, v in element_dict.items()}\n",
        "        fractions = [Fraction(v).limit_denominator() for v in element_dict.values()]\n",
        "        denominators = [f.denominator for f in fractions]\n",
        "\n",
        "        lcm = 1\n",
        "        for d in denominators:\n",
        "            lcm = lcm * d // gcd(lcm, d)\n",
        "\n",
        "        formula = ''\n",
        "        for elem, val in element_dict.items():\n",
        "            num = int(round(val * lcm))\n",
        "            formula += f\"{elem}{num if num > 1 else ''}\"\n",
        "\n",
        "        return normalize_formula(formula)\n",
        "    except:\n",
        "        return 'Non-standard'\n",
        "\n",
        "def get_jid_fast(formula):\n",
        "    \"\"\"Fast lookup from pre-computed formula_to_jid dict, includes normalized fallback.\"\"\"\n",
        "    if not formula or not isinstance(formula, str):\n",
        "        return \"Invalid input\"\n",
        "    jid = formula_to_jid.get(formula)\n",
        "    if jid:\n",
        "        return jid\n",
        "    normalized = normalize_formula(formula)\n",
        "    return formula_to_jid.get(normalized, f\"No JID found for formula '{formula}'\")\n",
        "\n",
        "def JID_to_csv(df, excel_name):\n",
        "    formulas = []\n",
        "    for item in df['Extracted_name']:\n",
        "        try:\n",
        "            formula_list = ast.literal_eval(item)\n",
        "            formula_dict = formula_list[0]  # First dict in list\n",
        "            formula = generate_empirical_formula_from_dict(formula_dict)\n",
        "        except Exception as e:\n",
        "            formula = 'Non-standard'\n",
        "        formulas.append(formula)\n",
        "\n",
        "    # Generate dataframe\n",
        "    formulas_df = pd.DataFrame({'Formula': formulas})\n",
        "    mask_valid = formulas_df['Formula'] != 'Non-standard'\n",
        "    formulas_df.loc[mask_valid, 'jid'] = formulas_df.loc[mask_valid, 'Formula'].map(get_jid_fast)\n",
        "\n",
        "    # Combine with original DataFrame\n",
        "    df = df.reset_index(drop=True)\n",
        "    formulas_df = formulas_df.reset_index(drop=True)\n",
        "    df['Formula'] = formulas_df['Formula']\n",
        "    df['jid'] = formulas_df['jid']\n",
        "\n",
        "    # Write to Excel\n",
        "    df.to_excel(f'/content/drive/MyDrive/pre-processed2/{excel_name}.xlsx', index=False)\n"
      ],
      "metadata": {
        "id": "w7PNW3r2x9sW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nl_TwVs16GpV"
      },
      "outputs": [],
      "source": [
        "JID_to_csv(voltage,'voltage')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rvHCeTJc6Y1A"
      },
      "outputs": [],
      "source": [
        "JID_to_csv(capacity,'capacity')\n",
        "JID_to_csv(energy,'energy')\n",
        "JID_to_csv(columbic,'columbic_efficiency')\n",
        "JID_to_csv(conductivity,'conductivity')\n",
        "JID_to_csv(voltage_capacity,'voltage_capacity')\n",
        "JID_to_csv(voltage_conductivity,'voltage_conductivity')\n",
        "JID_to_csv(voltage_energy,'voltage_energy')\n",
        "JID_to_csv(voltage_columbic,'voltage_columbic')\n",
        "JID_to_csv(capacity_conductivity,'capacity_conductivity')\n",
        "JID_to_csv(capacity_energy,'capacity_energy')\n",
        "JID_to_csv(capacity_columbic,'capacity_columbic-efficiency')\n",
        "JID_to_csv(conductivity_energy,'conductivity_energy')\n",
        "JID_to_csv(conductivity_columbic,'conductivity_columbic')\n",
        "JID_to_csv(energy_columbic,'energy_columbic-efficiency')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "aDLh_aZAp5xD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wRSIA0AWXBxa"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
